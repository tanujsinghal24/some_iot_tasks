{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Oxford: Emotion analysis example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Jupyter notebook shows you how to get started with the Project Oxford <b>Emotion API</b> in Python, and how to visualize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this notebook, you will need to get keys to <b>Emotion API</b>. Visit <a href=\"http://www.projectoxford.ai/emotion\">www.projectoxford.ai/emotion</a>, and then the “Try for free” button. On the “Sign in” page, use your Microsoft account to sign in and you will be able to subscribe to Emotion API and get free keys (Code of Conduct and TOS). After completing the sign-up process, paste your key into the variables section below. (Either the primary or the secondary key works.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time \n",
    "import requests\n",
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "# Import library to display results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Display images within Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "# Put in your own key\n",
    "\n",
    "_url = 'https://api.projectoxford.ai/emotion/v1.0/recognize'\n",
    "_key = '17e11073b0f643cbb4cc871f4256a5d4' #Here you have to paste your primary key\n",
    "_maxNumRetries = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processRequest( json, data, headers, params ):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper function to process the request to Project Oxford\n",
    "\n",
    "    Parameters:\n",
    "    json: Used when processing images from its URL. See API Documentation\n",
    "    data: Used when processing image read from disk. See API Documentation\n",
    "    headers: Used to pass the key information and the data type request\n",
    "    \"\"\"\n",
    "\n",
    "    retries = 0\n",
    "    result = None\n",
    "\n",
    "    while True:\n",
    "\n",
    "        response = requests.request( 'post', _url, json = json, data = data, headers = headers, params = params )\n",
    "\n",
    "        if response.status_code == 429: \n",
    "\n",
    "            print( \"Message: %s\" % ( response.json()['error']['message'] ) )\n",
    "\n",
    "            if retries <= _maxNumRetries: \n",
    "                time.sleep(1) \n",
    "                retries += 1\n",
    "                continue\n",
    "            else: \n",
    "                print( 'Error: failed after retrying!' )\n",
    "                break\n",
    "\n",
    "        elif response.status_code == 200 or response.status_code == 201:\n",
    "\n",
    "            if 'content-length' in response.headers and int(response.headers['content-length']) == 0: \n",
    "                result = None \n",
    "            elif 'content-type' in response.headers and isinstance(response.headers['content-type'], str): \n",
    "                if 'application/json' in response.headers['content-type'].lower(): \n",
    "                    result = response.json() if response.content else None \n",
    "                elif 'image' in response.headers['content-type'].lower(): \n",
    "                    result = response.content\n",
    "        else:\n",
    "            print( \"Error code: %d\" % ( response.status_code ) )\n",
    "            print( \"Message: %s\" % ( response.json()['error']['message'] ) )\n",
    "\n",
    "        break\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def renderResultOnImage( result, img ):\n",
    "    \n",
    "    \"\"\"Display the obtained results onto the input image\"\"\"\n",
    "    \n",
    "    for currFace in result:\n",
    "        faceRectangle = currFace['faceRectangle']\n",
    "        cv2.rectangle( img,(faceRectangle['left'],faceRectangle['top']),\n",
    "                           (faceRectangle['left']+faceRectangle['width'], faceRectangle['top'] + faceRectangle['height']),\n",
    "                       color = (255,0,0), thickness = 5 )\n",
    "\n",
    "\n",
    "    for currFace in result:\n",
    "        faceRectangle = currFace['faceRectangle']\n",
    "        currEmotion = max(currFace['scores'].items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "\n",
    "        textToWrite = \"%s\" % ( currEmotion )\n",
    "        cv2.putText( img, textToWrite, (faceRectangle['left'],faceRectangle['top']-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect faces from an image retrieved via URL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# URL direction to image\n",
    "urlImage = 'https://raw.githubusercontent.com/Microsoft/ProjectOxford-ClientSDK/master/Face/Windows/Data/detection3.jpg'\n",
    "\n",
    "headers = dict()\n",
    "headers['Ocp-Apim-Subscription-Key'] = _key\n",
    "headers['Content-Type'] = 'application/json' \n",
    "\n",
    "json = { 'url': urlImage } \n",
    "data = None\n",
    "params = None\n",
    "\n",
    "result = processRequest( json, data, headers, params )\n",
    "\n",
    "if result is not None:\n",
    "    # Load the original image, fetched from the URL\n",
    "    arr = np.asarray( bytearray( requests.get( urlImage ).content ), dtype=np.uint8 )\n",
    "    img = cv2.cvtColor( cv2.imdecode( arr, -1 ), cv2.COLOR_BGR2RGB )\n",
    "\n",
    "    renderResultOnImage( result, img )\n",
    "\n",
    "    ig, ax = plt.subplots(figsize=(15, 20))\n",
    "    ax.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load images from disk\n",
    "# image_directory is the location of the resized or actual images\n",
    "image_directory =  r'.'\n",
    "filelist =  glob.glob(image_directory +'/*.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test to make sure you are getting the correct file. Will only print out the first one\n",
    "len(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'91a.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to test the split - we want to save the filename\n",
    "os.path.split(filelist[1])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect faces from an image stored on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load raw image file into memory\n",
    "\n",
    "def bing_emotion(filelist):\n",
    "\n",
    "    pathToFileInDisk = filelist\n",
    "\n",
    "    with open( pathToFileInDisk, 'rb' ) as f:\n",
    "        data = f.read()\n",
    "\n",
    "    headers = dict()\n",
    "    headers['Ocp-Apim-Subscription-Key'] = _key\n",
    "    headers['Content-Type'] = 'application/octet-stream'\n",
    "\n",
    "    json = None\n",
    "    params = None\n",
    "\n",
    "    result = processRequest( json, data, headers, params )\n",
    "\n",
    "    if result is not None and len(result)> 0:\n",
    "        # Load the original image from disk\n",
    "        #data8uint = np.fromstring( data, np.uint8 ) # Convert string to an unsigned int array\n",
    "        #img = cv2.cvtColor( cv2.imdecode( data8uint, cv2.IMREAD_COLOR ), cv2.COLOR_BGR2RGB )\n",
    "\n",
    "        #renderResultOnImage( result, img )\n",
    "\n",
    "        #ig, ax = plt.subplots(figsize=(15, 20))\n",
    "        #ax.imshow( img )\n",
    "        \n",
    "        currEmotion = max(result[0]['scores'].items(), key=operator.itemgetter(1))[0]\n",
    "        \n",
    "        return pd.Series((os.path.split(pathToFileInDisk)[1],currEmotion ), index=['Image', 'Emotion'])\n",
    "        #print (len(result))\n",
    "        #return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the dataframe 'edata' to store the image name and emotion\n",
    "edata = pd.DataFrame(columns = ['Image', 'Emotion'])\n",
    "\n",
    "# Code to re-load the saved edata file (have to use batches if you dont want to run it for a long period)\n",
    "#edata = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through the files will only do 10 for now\n",
    "#for f in filelist[:10]:\n",
    "for f in filelist:\n",
    "    w = bing_emotion(f)\n",
    "    if w is not None:\n",
    "        edata = edata.append(w, ignore_index=True)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> NA.SU2.209.jpg</td>\n",
       "      <td>  surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> TM.AN2.191.jpg</td>\n",
       "      <td>   neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> TM.HA2.181.jpg</td>\n",
       "      <td> happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> KL.SU2.165.jpg</td>\n",
       "      <td>  surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> TM.NE2.178.jpg</td>\n",
       "      <td>   neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image    Emotion\n",
       "0  NA.SU2.209.jpg   surprise\n",
       "1  TM.AN2.191.jpg    neutral\n",
       "2  TM.HA2.181.jpg  happiness\n",
       "3  KL.SU2.165.jpg   surprise\n",
       "4  TM.NE2.178.jpg    neutral\n",
       "\n",
       "[5 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code to save the edata either as csv or pickle\n",
    "#file_name =  r'C:\\Users\\Jare_2\\OneDrive\\WorkDocs\\CUNY\\622\\Group_Project\\Images\\ifw\\emotion_data.p'\n",
    "#edata.to_pickle(file_name)\n",
    "\n",
    "# CSV format\n",
    "edata.to_csv(\"solution_raw.csv\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if you have duplicates\n",
    "edata = edata.drop_duplicates('Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aaron_Peirsol_0003.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aaron_Peirsol_0004.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aaron_Pena_0001.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aaron_Sorkin_0001.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aaron_Sorkin_0002.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Image    Emotion\n",
       "5  Aaron_Peirsol_0003.jpg  happiness\n",
       "6  Aaron_Peirsol_0004.jpg    neutral\n",
       "7     Aaron_Pena_0001.jpg    neutral\n",
       "8   Aaron_Sorkin_0001.jpg  happiness\n",
       "9   Aaron_Sorkin_0002.jpg  happiness"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edata.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
